{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = \"/home/bmazoyer/Documents/Data/police/medias_unique/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(input_image):\n",
    "    image = input_image.convert(\"RGB\")  # in case input image is not in RGB format\n",
    "    img_t = transform(image)\n",
    "    batch_t = torch.unsqueeze(img_t, 0)\n",
    "    my_embedding = torch.zeros([1, 512, 1, 1])\n",
    "    def copy_data(m, i, o):\n",
    "        my_embedding.copy_(o.data)\n",
    "    h = layer.register_forward_hook(copy_data)\n",
    "    model(batch_t)\n",
    "    h.remove()\n",
    "    return my_embedding.squeeze().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "layer = model._modules.get('avgpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_names = [os.path.join(root, name)\n",
    "            for root, dirs, files in os.walk(im_path)\n",
    "            for name in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_images_df = pd.DataFrame([re.findall(r\"[\\w']+\", im_name)[1:3] for im_name in im_names],\n",
    "                                  columns=['cat_id', 'pid'])\n",
    "existing_images_df['impath'] = im_names\n",
    "existing_images_df = existing_images_df.sample(n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = [list(get_vector(Image.open(impath))) for _, pid, impath in existing_images_df.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vis/feature_vecs.tsv', 'w') as fw:\n",
    "    csv_writer = csv.writer(fw, delimiter='\\t')\n",
    "    csv_writer.writerows(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [Image.open(filename).resize((300,300)) for filename in existing_images_df['impath']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width, image_height = images[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_square_size = int(np.ceil(np.sqrt(len(images))))\n",
    "master_width = (image_width * one_square_size) \n",
    "master_height = image_height * one_square_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "spriteimage = Image.new(\n",
    "    mode='RGBA',\n",
    "    size=(master_width, master_height),\n",
    "    color=(0,0,0,0))  # fully transparent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count, image in enumerate(images):\n",
    "    div, mod = divmod(count,one_square_size)\n",
    "    h_loc = image_width*div\n",
    "    w_loc = image_width*mod    \n",
    "    spriteimage.paste(image,(w_loc,h_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "spriteimage.convert(\"RGB\").save('vis/sprite.jpg', transparency=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-47-bfd0f17e5484>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-47-bfd0f17e5484>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    embeddings {\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "embeddings {\n",
    "  tensor_path: \"feature_vecs.tsv\"\n",
    "  sprite {\n",
    "    image_path: \"sprite.jpg\"\n",
    "    single_image_dim: 50\n",
    "    single_image_dim: 50\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
